{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=19.30s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(annotation_file=\"/scratch/lt2316-h18-resources/coco/annotations/instances_train2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cat = coco.getCatIds(catNms=\"cat\")\n",
    "horse_cat = coco.getCatIds(catNms=\"horse\")\n",
    "sheep_cat = coco.getCatIds(catNms=\"sheep\")\n",
    "bird_cat = coco.getCatIds(catNms=\"bird\")\n",
    "dog_cat = coco.getCatIds(catNms=\"dog\")\n",
    "bear_cat = coco.getCatIds(catNms=\"bear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([17], [19], [23])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cat, horse_cat, bear_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imgs = coco.getImgIds(catIds=cat_cat)\n",
    "horse_imgs = coco.getImgIds(catIds=horse_cat)\n",
    "sheep_imgs = coco.getImgIds(catIds=sheep_cat)\n",
    "bird_imgs = coco.getImgIds(catIds=bird_cat)\n",
    "dog_imgs = coco.getImgIds(catIds=dog_cat)\n",
    "bear_imgs = coco.getImgIds(catIds=bear_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(cat_imgs)\n",
    "cat_imgs_train = cat_imgs[:2200]\n",
    "cat_imgs_val = cat_imgs[2200:2420]\n",
    "cat_imgs_test = cat_imgs[2420:2640]\n",
    "\n",
    "\n",
    "random.shuffle(horse_imgs)\n",
    "horse_imgs_train = horse_imgs[:2200]\n",
    "horse_imgs_test = horse_imgs[2200:2420]\n",
    "horse_imgs_val = horse_imgs[2420:2640]\n",
    "\n",
    "random.shuffle(sheep_imgs)\n",
    "sheep_imgs_train = sheep_imgs[:1223]\n",
    "sheep_imgs_test = sheep_imgs[1223:1376]\n",
    "sheep_imgs_val = sheep_imgs[1376:1529]\n",
    "\n",
    "random.shuffle(bird_imgs)\n",
    "bird_imgs_train = bird_imgs[:2200]\n",
    "bird_imgs_test = bird_imgs[2200:2420]\n",
    "bird_imgs_val = bird_imgs[2420:2640]\n",
    "\n",
    "random.shuffle(dog_imgs)\n",
    "dog_imgs_train = dog_imgs[:2200]\n",
    "dog_imgs_test = dog_imgs[2200:2420]\n",
    "dog_imgs_val = dog_imgs[2420:2640]\n",
    "\n",
    "random.shuffle(bear_imgs)\n",
    "bear_imgs_train = bear_imgs[:768]\n",
    "bear_imgs_test = bear_imgs[768:864]\n",
    "bear_imgs_val = bear_imgs[864:960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 2200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bear_imgs_train), len(dog_imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in cat_imgs[0:600] if x in horse_imgs[0:600]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_meta_train = coco.loadImgs(ids=cat_imgs_train)\n",
    "cat_meta_test = coco.loadImgs(ids=cat_imgs_test)\n",
    "horse_meta_train = coco.loadImgs(ids=horse_imgs_train)\n",
    "horse_meta_test = coco.loadImgs(ids=horse_imgs_test)\n",
    "cat_meta_val = coco.loadImgs(ids=cat_imgs_val)\n",
    "horse_meta_val = coco.loadImgs(ids=horse_imgs_val)\n",
    "\n",
    "sheep_meta_train = coco.loadImgs(ids=sheep_imgs_train)\n",
    "sheep_meta_test = coco.loadImgs(ids=sheep_imgs_test)\n",
    "bird_meta_train = coco.loadImgs(ids=bird_imgs_train)\n",
    "bird_meta_test = coco.loadImgs(ids=bird_imgs_test)\n",
    "sheep_meta_val = coco.loadImgs(ids=sheep_imgs_val)\n",
    "bird_meta_val = coco.loadImgs(ids=bird_imgs_val)\n",
    "\n",
    "dog_meta_train = coco.loadImgs(ids=dog_imgs_train)\n",
    "dog_meta_test = coco.loadImgs(ids=dog_imgs_test)\n",
    "bear_meta_train = coco.loadImgs(ids=bear_imgs_train)\n",
    "bear_meta_test = coco.loadImgs(ids=bear_imgs_test)\n",
    "dog_meta_val = coco.loadImgs(ids=dog_imgs_val)\n",
    "bear_meta_val = coco.loadImgs(ids=bear_imgs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(meta, datadir=\"/scratch/lt2316-h18-resources/coco/train2017\"):\n",
    "    return [(x['file_name'], Image.open(\"{}/{}\".format(datadir, x['file_name'])).resize((100,100))) for x in meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data_train = get_data(cat_meta_train)\n",
    "horse_data_train = get_data(horse_meta_train)\n",
    "cat_data_test = get_data(cat_meta_test)\n",
    "horse_data_test = get_data(horse_meta_test)\n",
    "cat_data_val = get_data(cat_meta_val)\n",
    "horse_data_val = get_data(horse_meta_val)\n",
    "\n",
    "bird_data_train = get_data(bird_meta_train)\n",
    "sheep_data_train = get_data(sheep_meta_train)\n",
    "bird_data_test = get_data(bird_meta_test)\n",
    "sheep_data_test = get_data(sheep_meta_test)\n",
    "bird_data_val = get_data(bird_meta_val)\n",
    "sheep_data_val = get_data(sheep_meta_val)\n",
    "\n",
    "bear_data_train = get_data(bear_meta_train)\n",
    "dog_data_train = get_data(dog_meta_train)\n",
    "bear_data_test = get_data(bear_meta_test)\n",
    "dog_data_test = get_data(dog_meta_test)\n",
    "bear_data_val = get_data(bear_meta_val)\n",
    "dog_data_val = get_data(dog_meta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data_train_df = pd.DataFrame(cat_data_train)\n",
    "cat_data_train_df['class'] = 'cat'\n",
    "\n",
    "horse_data_train_df = pd.DataFrame(horse_data_train)\n",
    "horse_data_train_df['class'] = 'horse'\n",
    "\n",
    "cat_data_test_df = pd.DataFrame(cat_data_test)\n",
    "cat_data_test_df['class'] = 'cat'\n",
    "\n",
    "horse_data_test_df = pd.DataFrame(horse_data_test)\n",
    "horse_data_test_df['class'] = 'horse'\n",
    "\n",
    "cat_data_val_df = pd.DataFrame(cat_data_val)\n",
    "cat_data_val_df['class'] = 'cat'\n",
    "\n",
    "horse_data_val_df = pd.DataFrame(horse_data_val)\n",
    "horse_data_val_df['class'] = 'horse'\n",
    "\n",
    "\n",
    "sheep_data_train_df = pd.DataFrame(sheep_data_train)\n",
    "sheep_data_train_df['class'] = 'sheep'\n",
    "\n",
    "bird_data_train_df = pd.DataFrame(bird_data_train)\n",
    "bird_data_train_df['class'] = 'bird'\n",
    "\n",
    "sheep_data_test_df = pd.DataFrame(sheep_data_test)\n",
    "sheep_data_test_df['class'] = 'sheep'\n",
    "\n",
    "bird_data_test_df = pd.DataFrame(bird_data_test)\n",
    "bird_data_test_df['class'] = 'bird'\n",
    "\n",
    "sheep_data_val_df = pd.DataFrame(sheep_data_val)\n",
    "sheep_data_val_df['class'] = 'sheep'\n",
    "\n",
    "bird_data_val_df = pd.DataFrame(bird_data_val)\n",
    "bird_data_val_df['class'] = 'bird'\n",
    "\n",
    "\n",
    "dog_data_train_df = pd.DataFrame(dog_data_train)\n",
    "dog_data_train_df['class'] = 'dog'\n",
    "\n",
    "bear_data_train_df = pd.DataFrame(bear_data_train)\n",
    "bear_data_train_df['class'] = 'bear'\n",
    "\n",
    "dog_data_test_df = pd.DataFrame(dog_data_test)\n",
    "dog_data_test_df['class'] = 'dog'\n",
    "\n",
    "bear_data_test_df = pd.DataFrame(bear_data_test)\n",
    "bear_data_test_df['class'] = 'bear'\n",
    "\n",
    "dog_data_val_df = pd.DataFrame(dog_data_val)\n",
    "dog_data_val_df['class'] = 'dog'\n",
    "\n",
    "bear_data_val_df = pd.DataFrame(bear_data_val)\n",
    "bear_data_val_df['class'] = 'bear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([cat_data_train_df, horse_data_train_df,dog_data_train_df, sheep_data_train_df,bird_data_train_df, bear_data_train_df])\n",
    "test_df = pd.concat([cat_data_test_df, horse_data_test_df,sheep_data_test_df, bird_data_test_df,dog_data_test_df, bear_data_test_df])\n",
    "val_df =pd.concat([cat_data_val_df, horse_data_val_df,sheep_data_val_df, bird_data_val_df,dog_data_val_df, bear_data_val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>imgs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000283505.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000406422.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000561582.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000052925.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000573877.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>000000437604.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>000000347529.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>000000564920.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>000000497042.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>000000521236.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>bear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10781 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Path                                               imgs label\n",
       "0    000000283505.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   cat\n",
       "1    000000406422.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   cat\n",
       "2    000000561582.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   cat\n",
       "3    000000052925.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   cat\n",
       "4    000000573877.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   cat\n",
       "..                ...                                                ...   ...\n",
       "753  000000437604.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...  bear\n",
       "754  000000347529.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...  bear\n",
       "755  000000564920.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...  bear\n",
       "756  000000497042.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...  bear\n",
       "757  000000521236.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...  bear\n",
       "\n",
       "[10781 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.rename(columns={0: 'Path', 1: 'imgs', 'class':'label'}, inplace=True)\n",
    "test_df.rename(columns={0: 'Path', 1: 'imgs', 'class':'label'}, inplace=True)\n",
    "val_df.rename(columns={0: 'Path', 1: 'imgs', 'class':'label'}, inplace=True)\n",
    "train_df.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'horse' 'dog' 'sheep' 'bird' 'bear']\n"
     ]
    }
   ],
   "source": [
    "# Getting the unique labels\n",
    "labels = train_df['label'].unique()\n",
    "\n",
    "print(labels)\n",
    "\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
    "\n",
    "size = (\n",
    "\n",
    "    image_processor.size[\"shortest_edge\"]\n",
    "\n",
    "    if \"shortest_edge\" in image_processor.size\n",
    "\n",
    "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
    "\n",
    ")\n",
    "\n",
    "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class CustomDatasetCOCO(Dataset):\n",
    "    def __init__(self, dataframe, transforms=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transforms = transforms\n",
    "        label_mapping = {'cat': 0, 'horse': 1, 'dog': 2, 'sheep': 3, 'bird': 4, 'bear': 5}\n",
    "        self.dataframe['label'] = self.dataframe['label'].apply(lambda x: label_mapping.get(x, -1))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataframe.iloc[idx]['imgs']\n",
    "        label = torch.tensor(self.dataframe.iloc[idx]['label'], dtype=torch.long)\n",
    "        \n",
    "                # Ensure image is RGB\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return {'pixel_values': image, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDatasetCOCO(dataframe=train_df, transforms=_transforms)\n",
    "dataset_test = CustomDatasetCOCO(dataframe=test_df, transforms=_transforms)\n",
    "dataset_val = CustomDatasetCOCO(dataframe=val_df, transforms=_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys: dict_keys(['pixel_values', 'label'])\n",
      "Image type: <class 'torch.Tensor'>\n",
      "Label type: <class 'torch.Tensor'>\n",
      "Label: tensor(5)\n",
      "Image mode: RGB\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "sample = dataset_test[-10]\n",
    "print(\"Sample keys:\", sample.keys())\n",
    "print(\"Image type:\", type(sample['pixel_values']))\n",
    "print(\"Label type:\", type(sample['label']))\n",
    "print(\"Label:\", sample['label'])\n",
    "\n",
    "image = sample['pixel_values']\n",
    "\n",
    "# Converting from torch tensor back to PIL image for checking the mode\n",
    "image = torchvision.transforms.ToPILImage()(image)\n",
    "\n",
    "print(\"Image mode:\", image.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = int(len(id2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'cat', '1': 'horse', '2': 'dog', '3': 'sheep', '4': 'bird', '5': 'bear'}\n"
     ]
    }
   ],
   "source": [
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "\n",
    "    checkpoint,\n",
    "\n",
    "    num_labels=len(labels),\n",
    "\n",
    "    id2label=id2label,\n",
    "\n",
    "    label2id=label2id,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guslasbo@GU.GU.SE/miniconda3/envs/Assignment1_ML/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 06:04, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.161200</td>\n",
       "      <td>1.060622</td>\n",
       "      <td>0.756422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.763039</td>\n",
       "      <td>0.798051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.675400</td>\n",
       "      <td>0.691268</td>\n",
       "      <td>0.811337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guslasbo@GU.GU.SE/miniconda3/envs/Assignment1_ML/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/guslasbo@GU.GU.SE/miniconda3/envs/Assignment1_ML/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=126, training_loss=0.9972751783946204, metrics={'train_runtime': 370.2193, 'train_samples_per_second': 87.443, 'train_steps_per_second': 0.34, 'total_flos': 2.495796490457948e+18, 'train_loss': 0.9972751783946204, 'epoch': 2.98})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\n",
    "    output_dir=\"my_awesome_multiclass_model\",\n",
    "\n",
    "    remove_unused_columns=False,\n",
    "\n",
    "    evaluation_strategy=\"epoch\",\n",
    "\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    gradient_accumulation_steps=4,\n",
    "\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    logging_steps=10,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "\n",
    "    push_to_hub=False,\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = val_df\n",
    "\n",
    "image = ds.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path                                      000000435698.jpg\n",
      "imgs     <PIL.Image.Image image mode=RGB size=100x100 a...\n",
      "label                                                    0\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ds.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=100x100 at 0x7F829183F0A0>\n"
     ]
    }
   ],
   "source": [
    "print(image['imgs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.37481778860092163, 'label': 'bear'},\n",
       " {'score': 0.21255673468112946, 'label': 'bird'},\n",
       " {'score': 0.18375423550605774, 'label': 'cat'},\n",
       " {'score': 0.1049196794629097, 'label': 'dog'},\n",
       " {'score': 0.06941524893045425, 'label': 'horse'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"image-classification\", model=\"./my_awesome_multiclass_model/checkpoint-126\")\n",
    "\n",
    "classifier(image['imgs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "import torch\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"./my_awesome_multiclass_model/checkpoint-126\")\n",
    "\n",
    "inputs = image_processor(image['imgs'], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"./my_awesome_multiclass_model/checkpoint-126\")\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bear'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label = logits.argmax(-1).item()\n",
    "\n",
    "model.config.id2label[predicted_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
